{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document: I was sleeping in my room when I heard a loud noise\n",
      "\n",
      "\n",
      "Similar Documents:\n",
      "\n",
      "\n",
      "Document: While peacefully resting in my bedroom, I suddenly became aware of a resounding disturbance.\n",
      "Cosine Similarity : 0.0\n",
      "\n",
      "\n",
      "Document: Neural networks are artificial systems that were inspired by biological neural networks. These systems learn to perform tasks by being exposed to various datasets and examples without any task-specific rules. The idea is that the system generates identifying characteristics from the data they have been passed without being programmed with a pre-programmed understanding of these datasets. Neural networks are based on computational models for threshold logic.\n",
      "Cosine Similarity : 0.0\n",
      "\n",
      "\n",
      "Document: Machine learning approaches are traditionally divided into three broad categories, depending on the nature of the \"signal\"or \"feedback\" available to the learning system: Supervised, Unsupervised and Reinforcement\n",
      "Cosine Similarity : 0.0\n",
      "\n",
      "\n",
      "Document: Machine learning involves computers discovering how they can perform tasks without being explicitly programmed to do so. It involves computers learning from data provided so that they carry out certain tasks.\n",
      "Cosine Similarity : 0.0\n",
      "\n",
      "\n",
      "Document: Machine learning is closely related to computational statistics, which focuses on making predictions using computers.The study of mathematical optimization delivers methods, theory and application domains to the field of machine learning.\n",
      "Cosine Similarity : 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     c:\\Users\\kusha\\anaconda3\\share\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "\n",
    "# Sample corpus\n",
    "documents = [\"I was sleeping in my room when I heard a loud noise\",\n",
    "'Machine learning is closely related to computational statistics, which focuses on making predictions using computers.\\\n",
    "The study of mathematical optimization delivers methods, theory and application domains to the field of machine learning.',\n",
    "'Machine learning involves computers discovering how they can perform tasks without being explicitly programmed to do so. \\\n",
    "It involves computers learning from data provided so that they carry out certain tasks.',\n",
    "'Machine learning approaches are traditionally divided into three broad categories, depending on the nature of the \"signal\"\\\n",
    "or \"feedback\" available to the learning system: Supervised, Unsupervised and Reinforcement',\n",
    "'Neural networks are artificial systems that were inspired by biological neural networks. These systems learn to perform tasks by being exposed to various datasets and examples without any task-specific rules. The idea is that the system generates identifying characteristics from the data they have been passed without being programmed with a pre-programmed understanding of these datasets. Neural networks are based on computational models for threshold logic.',\n",
    "\"While peacefully resting in my bedroom, I suddenly became aware of a resounding disturbance.\"\n",
    "]\n",
    "\n",
    "documents_df=pd.DataFrame(documents,columns=['documents'])\n",
    "\n",
    "# removing special characters and stop words from the text\n",
    "stop_words_l=stopwords.words('english')\n",
    "documents_df['documents_cleaned']=documents_df.documents.apply(lambda x: \" \".join(re.sub(r'[^a-zA-Z]',' ',w).lower() for w in x.split() if re.sub(r'[^a-zA-Z]',' ',w).lower() not in stop_words_l) )\n",
    "\n",
    "tfidfvectoriser=TfidfVectorizer()\n",
    "tfidfvectoriser.fit(documents_df.documents_cleaned)\n",
    "tfidf_vectors=tfidfvectoriser.transform(documents_df.documents_cleaned)\n",
    "\n",
    "pairwise_similarities=np.dot(tfidf_vectors,tfidf_vectors.T).toarray()\n",
    "pairwise_differences=euclidean_distances(tfidf_vectors)\n",
    "\n",
    "def most_similar(doc_id,similarity_matrix,matrix):\n",
    "    print (f'Document: {documents_df.iloc[doc_id][\"documents\"]}')\n",
    "    print ('\\n')\n",
    "    print ('Similar Documents:')\n",
    "    if matrix=='Cosine Similarity':\n",
    "        similar_ix=np.argsort(similarity_matrix[doc_id])[::-1]\n",
    "    elif matrix=='Euclidean Distance':\n",
    "        similar_ix=np.argsort(similarity_matrix[doc_id])\n",
    "    for ix in similar_ix:\n",
    "        if ix==doc_id:\n",
    "            continue\n",
    "        print('\\n')\n",
    "        print (f'Document: {documents_df.iloc[ix][\"documents\"]}')\n",
    "        print (f'{matrix} : {similarity_matrix[doc_id][ix]}')\n",
    "\n",
    "most_similar(0,pairwise_similarities,'Cosine Similarity')\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kusha\\anaconda3\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document: I was sleeping in my room when I heard a loud noise\n",
      "\n",
      "\n",
      "Similar Documents:\n",
      "\n",
      "\n",
      "Document: While peacefully resting in my bedroom, I suddenly became aware of a resounding disturbance.\n",
      "Cosine Similarity : 0.7958956360816956\n",
      "\n",
      "\n",
      "Document: Machine learning involves computers discovering how they can perform tasks without being explicitly programmed to do so. It involves computers learning from data provided so that they carry out certain tasks.\n",
      "Cosine Similarity : 0.2711508274078369\n",
      "\n",
      "\n",
      "Document: Machine learning approaches are traditionally divided into three broad categories, depending on the nature of the \"signal\"or \"feedback\" available to the learning system: Supervised, Unsupervised and Reinforcement\n",
      "Cosine Similarity : 0.2642394006252289\n",
      "\n",
      "\n",
      "Document: Machine learning is closely related to computational statistics, which focuses on making predictions using computers.The study of mathematical optimization delivers methods, theory and application domains to the field of machine learning.\n",
      "Cosine Similarity : 0.216576486825943\n",
      "\n",
      "\n",
      "Document: Neural networks are artificial systems that were inspired by biological neural networks. These systems learn to perform tasks by being exposed to various datasets and examples without any task-specific rules. The idea is that the system generates identifying characteristics from the data they have been passed without being programmed with a pre-programmed understanding of these datasets. Neural networks are based on computational models for threshold logic.\n",
      "Cosine Similarity : 0.14146381616592407\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "sbert_model = SentenceTransformer('bert-base-nli-mean-tokens')\n",
    "\n",
    "document_embeddings = sbert_model.encode(documents_df['documents_cleaned'])\n",
    "\n",
    "pairwise_similarities=cosine_similarity(document_embeddings)\n",
    "pairwise_differences=euclidean_distances(document_embeddings)\n",
    "\n",
    "most_similar(0,pairwise_similarities,'Cosine Similarity')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
